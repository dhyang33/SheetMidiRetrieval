{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os.path\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importScoreInfo(scoreDir):\n",
    "    d = {}\n",
    "    for csvfile in glob.glob(\"{}/p*.scoreinfo.csv\".format(scoreDir)):\n",
    "        pieceStr = os.path.basename(csvfile).split('.')[0]  # e.g. 'p7'\n",
    "        d[pieceStr] = {}\n",
    "        with open(csvfile, 'r') as f:\n",
    "            next(f) # skip header\n",
    "            for line in f:\n",
    "                parts = line.rstrip().split(',')\n",
    "                linenum = int(parts[0])\n",
    "                startmeasure = int(parts[1])\n",
    "                endmeasure = int(parts[2])\n",
    "                d[pieceStr][linenum] = (startmeasure, endmeasure)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreDir = 'data/score_info'\n",
    "scoreInfo = importScoreInfo(scoreDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importMidiInfo(midiInfoDir, midiDir):\n",
    "    d = {}\n",
    "    for csvfile in glob.glob(\"{}/p*_midinfo.csv\".format(midiInfoDir)):\n",
    "        pieceStr = os.path.basename(csvfile).split('_')[0]  # e.g. 'p7'\n",
    "        d[pieceStr] = {}\n",
    "        with open(csvfile, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.rstrip().split(',')\n",
    "                measure = int(parts[0])\n",
    "                time = float(parts[1])\n",
    "                d[pieceStr][measure] = time\n",
    "        \n",
    "        # add an additional entry to indicate the total duration\n",
    "        midfile = \"{}/{}.mid\".format(midiDir, pieceStr)\n",
    "        mid = pretty_midi.PrettyMIDI(midfile)\n",
    "        totalDur = mid.get_piano_roll().shape[1] * .01 # default fs = 100\n",
    "        d[pieceStr][measure+1] = totalDur\n",
    "                \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyang/.conda/envs/MIR4/lib/python3.6/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "midiInfoDir = 'data/midi_info'\n",
    "midiDir = 'data/midi'\n",
    "midiInfo = importMidiInfo(midiInfoDir, midiDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQueryGroundTruth(infile, multMatchFile, scoreInfo, midiInfo):\n",
    "    # infers ground truth timestamps for each query\n",
    "    d = {}\n",
    "    with open(infile, 'r') as fin: \n",
    "        next(fin) # skip header\n",
    "        for line in fin:\n",
    "\n",
    "            # get start, end lines\n",
    "            parts = line.rstrip().split(',')  # e.g. 'p1_q1,0,3'\n",
    "            queryStr = parts[0]\n",
    "            startLine = int(parts[1])\n",
    "            endLine = int(parts[2])\n",
    "\n",
    "            # infer start, end measure\n",
    "            pieceStr = queryStr.split('_')[0]\n",
    "            #print(\"%s,%s,%s\" % (queryStr, startLine,endLine))            \n",
    "            startMeasure = scoreInfo[pieceStr][startLine][0]\n",
    "            endMeasure = scoreInfo[pieceStr][endLine][1]\n",
    "\n",
    "            # infer start, end time\n",
    "            #print(\"%s,%s,%s\" % (queryStr, startMeasure, endMeasure))\n",
    "            startTime = midiInfo[pieceStr][startMeasure]\n",
    "            endTime = midiInfo[pieceStr][endMeasure+1] # ends on downbeat of next measure\n",
    "\n",
    "            d[queryStr] = [(startTime, endTime, startMeasure, endMeasure, startLine, endLine)]\n",
    "\n",
    "    addMultipleMatches(d, multMatchFile, scoreInfo, midiInfo)\n",
    "            \n",
    "    return d                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMultipleMatches(d, multMatchFile, scoreInfo, midiInfo):\n",
    "    # some queries match more than 1 segment of the score, these are indicated in multMatchFile\n",
    "    with open(multMatchFile, 'r') as f:\n",
    "        for line in f:\n",
    "            \n",
    "            # parse line \n",
    "            parts = line.rstrip().split(',')  # e.g. 'p31_q8,L3m6,L5m1'\n",
    "            queryStr = parts[0]\n",
    "            pieceStr = queryStr.split('_')[0]\n",
    "            startStr = parts[1]\n",
    "            endStr = parts[2]\n",
    "            \n",
    "            # infer start, end measure\n",
    "            startLine = int(startStr.split('m')[0][1:])\n",
    "            endLine = int(endStr.split('m')[0][1:])\n",
    "            startOffset = int(startStr.split('m')[1])\n",
    "            endOffset = int(endStr.split('m')[1])\n",
    "            startMeasure = scoreInfo[pieceStr][startLine][0] + startOffset - 1\n",
    "            endMeasure = scoreInfo[pieceStr][endLine][0] + endOffset - 1\n",
    "            \n",
    "            # infer start, end time\n",
    "            startTime = midiInfo[pieceStr][startMeasure]\n",
    "            endTime = midiInfo[pieceStr][endMeasure+1] # ends on downbeat of next measure\n",
    "            \n",
    "            tup = (startTime, endTime, startMeasure, endMeasure, startStr, endStr) # startStr more informative than startLine\n",
    "            d[queryStr].append(tup)\n",
    "            \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveQueryInfoToFile(d, outfile):\n",
    "    with open(outfile, 'w') as f:\n",
    "        for query in sorted(d):\n",
    "            for (tstart, tend, mstart, mend, lstart, lend) in d[query]:\n",
    "                f.write('{},{:.2f},{:.2f},{},{},{},{}\\n'.format(query, tstart, tend, mstart, mend, lstart, lend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryInfoFile = 'data/query_info/query_info.csv' # to read\n",
    "multMatchesFile = 'data/query_info/query.multmatches' # to read\n",
    "queryGTFile = 'data/query_info/query.gt' # to write\n",
    "queryInfo = getQueryGroundTruth(queryInfoFile, multMatchesFile, scoreInfo, midiInfo)\n",
    "saveQueryInfoToFile(queryInfo, queryGTFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate system performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGroundTruthLabels(gtfile):\n",
    "    d = {}\n",
    "    with open(gtfile, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.rstrip().split(',') # e.g. 'p1_q1,1.55,32.59'\n",
    "            queryStr = parts[0]\n",
    "            tstart = float(parts[1])\n",
    "            tend = float(parts[2])\n",
    "            if queryStr in d:\n",
    "                d[queryStr].append((tstart, tend))\n",
    "            else:\n",
    "                d[queryStr] = [(tstart, tend)]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readHypothesisFiles(hypdir):\n",
    "    l = []\n",
    "    for hypfile in sorted(glob.glob(\"{}/*.hyp\".format(hypdir))):\n",
    "        with open(hypfile, 'r') as f:\n",
    "            line = next(f)\n",
    "            parts = line.rstrip().split(',')\n",
    "            query = parts[0]  # e.g. p1_q1\n",
    "            tstart = float(parts[1])\n",
    "            tend = float(parts[2])\n",
    "            l.append((query, tstart, tend))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPrecisionRecall(hypdir, gtfile):\n",
    "    d = readGroundTruthLabels(gtfile)\n",
    "    hyps = readHypothesisFiles(hypdir)\n",
    "    hypinfo = [] \n",
    "    overlapTotal, hypTotal, refTotal = (0,0,0)\n",
    "    for (queryid, hypstart, hypend) in hyps:\n",
    "        refSegments = d[queryid]\n",
    "        idxMax = 0\n",
    "        overlapMax = 0\n",
    "        for i, refSegment in enumerate(refSegments): # find ref segment with most overlap\n",
    "            overlap = calcOverlap((hypstart, hypend), refSegment)\n",
    "            if overlap > overlapMax:\n",
    "                idxMax = i\n",
    "                overlapMax = overlap\n",
    "        hyplen = hypend - hypstart\n",
    "        reflen = refSegments[idxMax][1] - refSegments[idxMax][0]        \n",
    "        overlapTotal += overlapMax\n",
    "        hypTotal += hyplen\n",
    "        refTotal += reflen\n",
    "        hypinfo.append((queryid, overlapMax, refSegments[idxMax][0], refSegments[idxMax][1], idxMax)) # keep for error analysis\n",
    "    P = overlapTotal / hypTotal\n",
    "    R = overlapTotal / refTotal\n",
    "    F = 2 * P * R / (P + R)\n",
    "    return F, P, R, hypinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcOverlap(seg1, seg2):\n",
    "    overlap_lb = max(seg1[0], seg2[0])\n",
    "    overlap_ub = min(seg1[1], seg2[1])\n",
    "    overlap = np.clip(overlap_ub - overlap_lb, 0, None)\n",
    "    return overlap    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypdir = 'experiments/total/hyp'\n",
    "F, P, R, hypinfo = calcPrecisionRecall(hypdir, queryGTFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, P, R, len(hypinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDebuggingInfo(hypdir, gtfile, scoreInfo, midiInfo, queryInfo, hypInfo):\n",
    "    d = readGroundTruthLabels(gtfile)\n",
    "    hyps = readHypothesisFiles(hypdir)\n",
    "    for i, (query, hyp_tstart, hyp_tend) in enumerate(hyps):\n",
    "        \n",
    "        # hyp and ref info (sec)\n",
    "        piece = query.split('_')[0]\n",
    "        _, overlap, ref_tstart, ref_tend, bestIdx = hypInfo[i]\n",
    "        \n",
    "        # hyp and ref info (measures)\n",
    "        interp_m = list(midiInfo[piece].keys())\n",
    "        interp_t = [midiInfo[piece][m] for m in interp_m]\n",
    "        hyp_mstart, hyp_mend, ref_mstart, ref_mend = np.interp([hyp_tstart, hyp_tend, ref_tstart, ref_tend], interp_t, interp_m)\n",
    "        moverlap = calcOverlap((hyp_mstart, hyp_mend),(ref_mstart, ref_mend))\n",
    "        \n",
    "        # hyp and ref info (line # + measure offset)\n",
    "        hyp_lstart, hyp_lstartoff = getLineNumberMeasureOffset(hyp_mstart, scoreInfo[piece])\n",
    "        hyp_lend, hyp_lendoff = getLineNumberMeasureOffset(hyp_mend, scoreInfo[piece])\n",
    "        ref_lstart = queryInfo[query][bestIdx][4]\n",
    "        ref_lend = queryInfo[query][bestIdx][5]\n",
    "        \n",
    "        # compare in sec\n",
    "        print(\"{}: hyp ({:.1f} s,{:.1f} s), ref ({:.1f} s,{:.1f} s), overlap {:.1f} of {:.1f} s\".format(query, hyp_tstart, hyp_tend, ref_tstart, ref_tend, overlap, ref_tend - ref_tstart))\n",
    "        \n",
    "        # compare in measure numbers\n",
    "        #print(\"\\thyp ({:.1f} m, {:.1f} m), ref ({:.1f} m, {:.1f} m), overlap {:.1f} m\".format(hyp_mstart, hyp_mend, ref_mstart, ref_mend, moverlap))\n",
    "        \n",
    "        # compare in line + measure offset\n",
    "        print(\"\\thyp (ln {} m{:.1f}, ln {} m{:.1f}), ref (ln {}, ln {})\".format(hyp_lstart, hyp_lstartoff, hyp_lend, hyp_lendoff, ref_lstart, ref_lend))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLineNumberMeasureOffset(measureNum, d):\n",
    "    line = -1\n",
    "    moffset = -1\n",
    "    for key in d:\n",
    "        lb, ub = d[key] # line start, end measure \n",
    "        if measureNum >= lb and measureNum < ub + 1:\n",
    "            line = key\n",
    "            moffset = measureNum - lb + 1\n",
    "            break\n",
    "    return line, moffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printDebuggingInfo(hypdir, queryGTFile, scoreInfo, midiInfo, queryInfo, hypinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showRuntimeStats(indir):\n",
    "    durs = []\n",
    "    cnt = 0\n",
    "    for hypfile in glob.glob('{}/*.hyp'.format(indir)):\n",
    "        cnt += 1\n",
    "        with open(hypfile, 'r') as f:\n",
    "            line = next(f)\n",
    "            parts = line.split(',')\n",
    "            dur = float(parts[3])\n",
    "            durs.append(dur)\n",
    "    durs = np.array(durs)\n",
    "    avgDur = np.mean(durs)\n",
    "    minDur = np.min(durs)\n",
    "    maxDur = np.max(durs)\n",
    "    stdDur = np.std(durs)\n",
    "    print('{} files'.format(cnt))\n",
    "    print('Avg Duration: {:.2f} sec'.format(avgDur))\n",
    "    print('Std Duration: {:.2f} sec'.format(stdDur))\n",
    "    print('Min Duration: {:.2f} sec'.format(minDur))\n",
    "    print('Max Duration: {:.2f} sec'.format(maxDur))\n",
    "    plt.hist(durs, bins=np.arange(0,2,.1))\n",
    "    plt.xlabel('Runtime (sec)')\n",
    "    plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showRuntimeStats(hypdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
